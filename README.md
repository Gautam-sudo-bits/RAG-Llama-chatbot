# RAG-based LLAMA Chatbot

A Retrieval-Augmented Generation (RAG) powered chatbot built using the **LangChain Orchestration Framework** and **open-source Hugging Face LLAMA models**. The system supports document-grounded Q\&A, where you can replace the dataset with your own PDFs and interact via a **Streamlit web app**.

---

## Repository Structure

```
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py              # Streamlit frontend UI
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ entry-page.png      # Screenshot of the welcome screen
â”‚   â””â”€â”€ qa-page.png         # Screenshot of a Q&A interaction
â”œâ”€â”€ data/
â”‚   â””â”€â”€ (Your PDFs here)    # Place your source documents in this folder
â”œâ”€â”€ rag_pipeline/
â”‚   â””â”€â”€ chain.py            # Core backend RAG logic and model loading
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ (Generated DB)      # FAISS vector index after ingest.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ ingest.py               # Script to build the vector database
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # You are here!
```

---

## Features

* Retrieval-Augmented chatbot with LLAMA-based embeddings and text generation.
* Pluggable dataset â€” replace `data/` with your own PDFs.
* Vector database generation using FAISS.
* Streamlit-powered web interface for easy interaction.

---

## Setup Instructions

### Clone the Repository

```bash
git clone https://github.com/your-username/your-repo.git
cd your-repo
```

### Install Dependencies

```bash
pip install -r requirements.txt
```

### Add Your Documents

* Place your **PDFs or text documents** inside the `data/` folder.

### Build the Vector Store

```bash
python ingest.py
```

This step creates the FAISS vector index inside `vectorstore/`.

### Launch the Streamlit App

```bash
streamlit run app/app.py
```

ðŸ“¸ **On successful run, you should see the entry page:**

![Entry Page](assets/entry-page.png)

### Chat with Your Documents

Type your question in the chat box. The chatbot retrieves relevant chunks from your documents and generates an answer.

 **Example Q\&A interaction:**

![Chatbot Q\&A](assets/qa-page.png)

---

## Tech Stack

* **LangChain Orchestration Framework**
* **LLAMA-based Hugging Face models**
* **FAISS** for vector search
* **Streamlit** for frontend
* **Python 3.9+**

---

## Notes

* Ensure you have **Python 3.9+** installed.
* Replace `data/` contents with your own files to customize the knowledge base.
* Rerun `ingest.py` every time you update your documents.

---

## License

This project is open-source under the MIT License.
